# ğŸ”’ Prompt Injection Beginner Project (Python)

This is a **beginner-friendly AI security project** that demonstrates:

- What **prompt injection** is  
- How an attacker can trick an AI model  
- How a vulnerable AI behaves  
- How to fix the issue using simple **sanitization**  
- Difference between **vulnerable AI** and **secure AI**  

You only need **one Python file** to run this project.

---

## ğŸš€ Project Overview

The project simulates two versions of an AI assistant:

### 1ï¸âƒ£ Vulnerable AI  
- Easily tricked by attacker prompts  
- Reveals secret information  
- Shows how real prompt injection attacks happen

### 2ï¸âƒ£ Secure AI  
- Sanitizes harmful inputs  
- Blocks dangerous prompts  
- Protects secrets

This makes it easy to understand **AI security basics** with very little code.
